{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 1,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "0603743c-6045-4112-b02c-d8da1a673a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.atlantafed.org/chcs/wage-growth-tracker\n"
     ]
    }
   ],
   "source": [
    "def WageGrowthTracker() -> str:\n",
    "    \"\"\"\n",
    "    Returns a link to solutions on GitHub.\n",
    "    \"\"\"\n",
    "    return \"https://www.atlantafed.org/chcs/wage-growth-tracker\"\n",
    "\n",
    "print(WageGrowthTracker())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 20,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "20b30acc-7e02-466c-a0e8-14fd6f0817e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Just for jupyter notebook - so I can avoid having to see big warning\n",
    "#   Note: if you want to disable and see warnings, see Zach's cells Q1 and \n",
    "#   comment out 'warnings.filterwarnings('ignore')'\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 3,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "e8e34a3f-b53c-4028-8678-e9a2ffbe377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and save the Excel file\n",
    "url = 'https://www.atlantafed.org/-/media/documents/datafiles/chcs/wage-growth-tracker/wage-growth-data.xlsx'\n",
    "with open('wage_growth_data.xlsx', 'wb') as file:\n",
    "    file.write(requests.get(url).content)\n",
    "\n",
    "# List of sheet names on Wage Growth excel sheet\n",
    "sheet_names = [\n",
    "    'Education', 'Age', 'Sex', 'Occupation', 'Industry', 'Census Divisions',\n",
    "    'Full-Time or Part-Time', 'Job Switcher', 'MSA or non-MSA', \n",
    "    'Average Wage Quartile', 'Paid Hourly', 'Overall 12ma', 'data_overall'\n",
    "]\n",
    "\n",
    "# Function to read sheets with different skiprows parameters\n",
    "#skip first row for data_overall tab, skip 2 rows on all other tabs\n",
    "def read_sheet(sheet):\n",
    "    skiprows = 1 if sheet == 'data_overall' else 2\n",
    "    return pd.read_excel('wage_growth_data.xlsx', sheet_name=sheet, skiprows=skiprows)\n",
    "\n",
    "# Merge sheets\n",
    "merged_df = pd.concat([read_sheet(sheet) for sheet in sheet_names], axis=1)\n",
    "\n",
    "# Save to a CSV file\n",
    "merged_df.to_csv('wageGrowth.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 4,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "e8c01807-a430-4f0c-8c10-63c597ac985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>High school of less</th>\n",
       "      <th>Associates degree</th>\n",
       "      <th>Bachelors degree or higher</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>16-24</th>\n",
       "      <th>25-54</th>\n",
       "      <th>55+</th>\n",
       "      <th>Overall.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Male.1</th>\n",
       "      <th>Job Stayer.1</th>\n",
       "      <th>Job Switcher.1</th>\n",
       "      <th>Paid Hourly.1</th>\n",
       "      <th>Overall: Weighted.1</th>\n",
       "      <th>Overall: Weighted 97.1</th>\n",
       "      <th>Overall: Weekly Basis</th>\n",
       "      <th>Overall: 25/20 trimmed mean</th>\n",
       "      <th>Lower 1/2 of wage distn</th>\n",
       "      <th>Upper 1/2 of wage distn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-01-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-04-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-04-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1997-05-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 High school of less Associates degree  \\\n",
       "0  1997-01-01                   .                 .   \n",
       "1  1997-02-01                   .                 .   \n",
       "2  1997-03-01                   .                 .   \n",
       "3  1997-04-01                   .                 .   \n",
       "4  1997-05-01                   .                 .   \n",
       "\n",
       "  Bachelors degree or higher Overall Unnamed: 0.1 16-24 25-54 55+ Overall.1  \\\n",
       "0                          .       .   1997-01-01     .     .   .         .   \n",
       "1                          .       .   1997-02-01     .     .   .         .   \n",
       "2                          .       .   1997-03-01     .     .   .         .   \n",
       "3                          .       .   1997-04-01     .     .   .         .   \n",
       "4                          .       .   1997-05-01     .     .   .         .   \n",
       "\n",
       "   ... Male.1 Job Stayer.1 Job Switcher.1 Paid Hourly.1 Overall: Weighted.1  \\\n",
       "0  ...      .            .              .             .                   .   \n",
       "1  ...      .            .              .             .                   .   \n",
       "2  ...    4.4          4.1            5.2           4.2                 4.9   \n",
       "3  ...    4.6          4.1            5.4           4.3                   5   \n",
       "4  ...    4.5          4.1            5.4           4.1                 4.9   \n",
       "\n",
       "  Overall: Weighted 97.1 Overall: Weekly Basis Overall: 25/20 trimmed mean  \\\n",
       "0                      .                     .                           .   \n",
       "1                      .                     .                           .   \n",
       "2                    4.9                   4.8                         4.5   \n",
       "3                      5                   4.9                         4.5   \n",
       "4                      5                   4.8                         4.4   \n",
       "\n",
       "  Lower 1/2 of wage distn Upper 1/2 of wage distn  \n",
       "0                       .                       .  \n",
       "1                       .                       .  \n",
       "2                     4.8                     4.2  \n",
       "3                     4.9                     4.2  \n",
       "4                       5                     4.1  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 17,
=======
     "execution_count": 4,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the Wage Growth Data Set\n",
    "merged_df = pd.read_csv('wageGrowth.csv')\n",
    "\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 5,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "b5348462-f21d-49df-b94e-26f355bc03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employmrent rate (not in final data set right now) \n",
    "url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=LREM64TTUSM156S&scale=left&cosd=1977-01-01&coed=2024-04-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-05-22&revision_date=2024-05-22&nd=1977-01-01\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#Rename the second column to be more clear\n",
    "df = df.rename(columns={df.columns[1]: 'Employment_Rate'})\n",
    "df = df.rename(columns={df.columns[0]: 'Date'})\n",
    "\n",
    "df.to_csv('Employment_Rate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 6,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "6726258b-9acf-4497-9269-ff5562bccbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date PresParty  SenParty HouseParty TrifectaFlag FedMinWage  \\\n",
      "0 1977-01-01  Democrat  Democrat   Democrat     Democrat      $2.30   \n",
      "1 1977-02-01  Democrat  Democrat   Democrat     Democrat      $2.30   \n",
      "2 1977-03-01  Democrat  Democrat   Democrat     Democrat      $2.30   \n",
      "3 1977-04-01  Democrat  Democrat   Democrat     Democrat      $2.30   \n",
      "4 1977-05-01  Democrat  Democrat   Democrat     Democrat      $2.30   \n",
      "\n",
      "  GDP_AnnualGrowth  Year  \n",
      "0            4.60%  1977  \n",
      "1            4.60%  1977  \n",
      "2            4.60%  1977  \n",
      "3            4.60%  1977  \n",
      "4            4.60%  1977  \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "minimumWage_Party = pd.read_csv('MinWage_PartyControl.csv').iloc[:, :6]\n",
    "minimumWage = pd.read_csv('MinimumWage.csv')\n",
    "selected_columns = minimumWage[['Year', 'GDP_AnnualGrowth']]  # Assuming 'Year' is already a column, not needing reset_index()\n",
    "\n",
    "# Merge the datasets\n",
    "merged_df = pd.merge(minimumWage_Party, selected_columns, on='Year', how='inner')\n",
    "filtered_df = merged_df[merged_df['Year'] > 1976]\n",
    "\n",
    "# Generate a DataFrame with all months for each year\n",
    "dates = pd.date_range(start=f\"{filtered_df['Year'].min()}-01-01\", end=f\"{filtered_df['Year'].max()}-12-31\", freq='MS')\n",
    "dates_df = pd.DataFrame({'Date': dates})\n",
    "\n",
    "# Merge the dates with the filtered DataFrame based on the year\n",
    "filtered_df = filtered_df.merge(dates_df, left_on='Year', right_on=dates_df['Date'].dt.year)\n",
    "\n",
    "# Reorder to make 'Date' the first column and rename it\n",
    "filtered_df.drop(columns=['Year'], inplace=True)\n",
    "filtered_df['Year'] = filtered_df['Date'].dt.year  # Recreate 'Year' if needed elsewhere\n",
    "filtered_df = filtered_df[['Date'] + [col for col in filtered_df.columns if col != 'Date']]\n",
    "\n",
    "# Save the final DataFrame\n",
    "filtered_df.to_csv('mergedMinimumWageData.csv', index=False)\n",
    "\n",
    "# Output the head of the final DataFrame to verify\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 7,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "6355968f-ef98-4745-b915-c365d1b54219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the dataset\n",
    "url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1138&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=IR3TIB01USM156N&scale=left&cosd=1964-06-01&coed=2024-04-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-05-20&revision_date=2024-05-20&nd=1964-06-01\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#Rename the second column to be more clear\n",
    "df.columns.values[1] = '3MonthInterestRate'\n",
    "\n",
    "df.to_csv('3-Month Interest Rates', index=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 8,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "2d2f7e58-cc6d-4fea-99ae-322c627a8aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>3MonthInterestRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964-06-01</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964-07-01</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1964-08-01</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964-09-01</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964-10-01</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE 3MonthInterestRate\n",
       "0  1964-06-01               3.86\n",
       "1  1964-07-01               3.87\n",
       "2  1964-08-01               3.85\n",
       "3  1964-09-01               3.87\n",
       "4  1964-10-01               3.94"
      ]
     },
<<<<<<< HEAD
     "execution_count": 21,
=======
     "execution_count": 8,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the 3 Month Interest Rates data sheet\n",
    "\n",
    "InterestRates = pd.read_csv('3-Month Interest Rates')\n",
    "\n",
    "InterestRates.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 9,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "a1963ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cpi csv\n",
    "cpi = pd.read_csv('cpi.csv')\n",
    "\n",
    "# omit first column\n",
    "cpi = cpi.iloc[:, 1:]\n",
    "\n",
    "# allows us to drop converting string to int type\n",
    "cpi['Year'] = cpi['Year'].astype(int)\n",
    "\n",
    "# sets year as index\n",
    "cpi = cpi.set_index(\"Year\")\n",
    "\n",
    "# drops all unnecessary years and columns\n",
    "cpi = cpi.drop(index = range(1913, 1996))\n",
    "cpi = cpi.drop(columns = [\"Avg\", \"Dec-Dec\", \"Avg-Avg\"])\n",
    "\n",
    "# 27 rows by 15 columns\n",
    "\n",
    "\n",
    "# use melt function from pandas to transform cpi df\n",
    "cpi_melted = cpi.reset_index().melt(id_vars='Year', var_name='Month', value_name='CPI')\n",
    "month_designation = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'June': '06',\n",
    "                     'July': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'}\n",
    "cpi_melted['Month'] = cpi_melted['Month'].map(month_designation)\n",
    "cpi_melted['Date'] = pd.to_datetime(cpi_melted['Year'].astype(str) + '-' + cpi_melted['Month'] + '-01')\n",
    "cpi_melted = cpi_melted.drop(columns=['Year', 'Month'])\n",
    "cpi_melted = cpi_melted.set_index('Date')\n",
    "cpi_melted = cpi_melted.sort_values('Date')\n",
    "\n",
    "# only include dates applicable to original df\n",
    "new_cpi = cpi_melted[cpi_melted.index < '2024-04-01']\n",
    "\n",
    "new_cpi.to_csv('new_cpi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 10,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "3df9625a-36e1-4948-8b88-f9d81a0b5d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date      CPI  MoM Change\n",
      "0    1996-01-01  154.400         NaN\n",
      "1    1996-02-01  154.900    0.323834\n",
      "2    1996-03-01  155.700    0.516462\n",
      "3    1996-04-01  156.300    0.385356\n",
      "4    1996-05-01  156.600    0.191939\n",
      "..          ...      ...         ...\n",
      "334  2023-11-01  307.051   -0.201514\n",
      "335  2023-12-01  306.746   -0.099332\n",
      "336  2024-01-01  308.417    0.544750\n",
      "337  2024-02-01  310.326    0.618967\n",
      "338  2024-03-01  312.332    0.646417\n",
      "\n",
      "[339 rows x 3 columns]\n",
      "           Date  MoM Change\n",
      "0    1996-01-01         NaN\n",
      "1    1996-02-01    0.323834\n",
      "2    1996-03-01    0.516462\n",
      "3    1996-04-01    0.385356\n",
      "4    1996-05-01    0.191939\n",
      "..          ...         ...\n",
      "334  2023-11-01   -0.201514\n",
      "335  2023-12-01   -0.099332\n",
      "336  2024-01-01    0.544750\n",
      "337  2024-02-01    0.618967\n",
      "338  2024-03-01    0.646417\n",
      "\n",
      "[339 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Nomrlaize CPI data above to be month over month, then creating a new datafram with only date and month over month claculations\n",
    "\n",
    "new_cpi = pd.read_csv('new_cpi.csv')\n",
    "\n",
    "# Calculate the month-over-month percentage change\n",
    "new_cpi['MoM Change'] = new_cpi['CPI'].pct_change() * 100\n",
    "\n",
    "print(new_cpi)\n",
    "\n",
    "selected_columns = new_cpi.reset_index()[['Date', 'MoM Change']]\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "selected_columns.to_csv('CPI_Month_Over_Month_Changes.csv', index=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 11,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "b38a5ced-388a-4471-9452-214566b0a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_10672\\4260192321.py:12: SettingWithCopyWarning: \n",
=======
      "/tmp/ipykernel_91/4260192321.py:12: SettingWithCopyWarning: \n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
<<<<<<< HEAD
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_10672\\4260192321.py:13: SettingWithCopyWarning: \n",
=======
      "/tmp/ipykernel_91/4260192321.py:13: SettingWithCopyWarning: \n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_InterestRates['Date'] = pd.to_datetime(filtered_InterestRates['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Load and filter the large DataFrame\n",
    "merged_df = pd.read_csv('wageGrowth.csv', parse_dates=[0])\n",
    "filtered_df = merged_df[merged_df.iloc[:, 0] > '1997-12-01']\n",
    "filtered_df.columns = ['Date'] + list(filtered_df.columns[1:])  # Rename the first column\n",
    "\n",
    "# Load and filter the 3-month interest rates DataFrame\n",
    "InterestRates = pd.read_csv('3-Month Interest Rates', parse_dates=[0])\n",
    "filtered_InterestRates = InterestRates[InterestRates.iloc[:, 0] > '1997-12-01']\n",
    "filtered_InterestRates.columns = ['Date'] + list(filtered_InterestRates.columns[1:])  # Rename the first column\n",
    "\n",
    "# Ensure that both 'Date' columns are in the datetime64[ns] format\n",
    "filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
    "filtered_InterestRates['Date'] = pd.to_datetime(filtered_InterestRates['Date'])\n",
    "\n",
    "# Merge the two filtered DataFrames on the \"Date\" column\n",
    "merged_final_df = pd.merge(filtered_df, filtered_InterestRates, on='Date')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_final_df.to_csv('merged_filtered_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 24,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "96161416-f779-4add-a279-94767eeb0a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  High school of less  Associates degree  \\\n",
      "0  1977-01-01                  NaN                NaN   \n",
      "1  1977-02-01                  NaN                NaN   \n",
      "2  1977-03-01                  NaN                NaN   \n",
      "3  1977-04-01                  NaN                NaN   \n",
      "4  1977-05-01                  NaN                NaN   \n",
      "\n",
      "   Bachelors degree or higher  Overall  16-24  25-54  55+  Overall.1  Male  \\\n",
      "0                         NaN      NaN    NaN    NaN  NaN        NaN   NaN   \n",
      "1                         NaN      NaN    NaN    NaN  NaN        NaN   NaN   \n",
      "2                         NaN      NaN    NaN    NaN  NaN        NaN   NaN   \n",
      "3                         NaN      NaN    NaN    NaN  NaN        NaN   NaN   \n",
      "4                         NaN      NaN    NaN    NaN  NaN        NaN   NaN   \n",
      "\n",
      "   ...  3MonthInterestRate  MoM Change  Employment_Rate  PresParty  SenParty  \\\n",
      "0  ...                 NaN         NaN         64.58551   Democrat  Democrat   \n",
      "1  ...                 NaN         NaN         64.70025   Democrat  Democrat   \n",
      "2  ...                 NaN         NaN         64.91437   Democrat  Democrat   \n",
      "3  ...                 NaN         NaN         65.15753   Democrat  Democrat   \n",
      "4  ...                 NaN         NaN         65.25849   Democrat  Democrat   \n",
      "\n",
      "   HouseParty  TrifectaFlag  FedMinWage  GDP_AnnualGrowth    Year  \n",
      "0    Democrat      Democrat       $2.30             4.60%  1977.0  \n",
      "1    Democrat      Democrat       $2.30             4.60%  1977.0  \n",
      "2    Democrat      Democrat       $2.30             4.60%  1977.0  \n",
      "3    Democrat      Democrat       $2.30             4.60%  1977.0  \n",
      "4    Democrat      Democrat       $2.30             4.60%  1977.0  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load initial merged and filtered data\n",
    "finalData = pd.read_csv('merged_filtered_data.csv')\n",
    "\n",
    "# Drop any 'Unnamed' columns that might be there due to indexing\n",
    "for i in range(13):\n",
    "    finalData = finalData.drop(columns=f\"Unnamed: 0.{i}\", errors='ignore')\n",
    "\n",
    "# Read in the new CPI data and merge\n",
    "newcpi = pd.read_csv('CPI_Month_Over_Month_Changes.csv')\n",
    "finalData = finalData.merge(newcpi, how='right', on='Date')\n",
    "\n",
    "# Read in the employment rate data and merge\n",
    "emplyRate = pd.read_csv('Employment_Rate.csv')\n",
    "finalData = finalData.merge(emplyRate, how='right', on='Date')\n",
    "\n",
    "# Read in the minimum wage data and merge\n",
    "minimumWage = pd.read_csv('mergedMinimumWageData.csv')\n",
    "finalData = finalData.merge(minimumWage, how='left', on='Date')\n",
    "\n",
    "# Save the final merged DataFrame to a new CSV file\n",
    "finalData.to_csv('finalData.csv', index=False)\n",
    "\n",
    "# Print the final merged DataFrame to verify the results\n",
    "print(finalData.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60161da6",
   "metadata": {},
   "source": [
    "Zach's Exploratory Data Analysis:\n",
    "\n",
    "I'm going to look at the relationships between a handful of variables and how \n",
    "they change over time, to get a better sense for the data we are working with."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 12,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "6b17174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Packages needed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd87944",
   "metadata": {},
   "source": [
    "Question 1:<br/>\n",
    "<br/>\n",
    "How did wage changes differ by certain divisions of people?<br/>\n",
    "a.) Male vs. Female<br/>\n",
    "b.) Income Quartiles<br/>\n",
    "c.) Mostly Full-Time Workers vs. Mostly Part-Time Workers<br/>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 13,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "8aa1b13d-4c40-46fc-854e-eccb1f97b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_changes_by_groups(data: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    docstring\n",
    "    \"\"\"\n",
    "    # Formatting data to what I need\n",
    "    cols_list = ['Date', 'Year', 'Overall', 'Male', 'Female', \n",
    "                 'Lowest quartile of wage distribution',\n",
    "                 '2nd quartile of wage distribution', \n",
    "                 '3rd quartile of wage distribution',\n",
    "                 'Highest quartile of wage distribution',\n",
    "                 'Usually Full-time', 'Usually Part-time']\n",
    "    df = data[cols_list]\n",
    "\n",
    "    # Visualization A - Difference in wage changes between males and females\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
   "id": "19c8768b-f121-4b00-a095-867a905534d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Overall.12   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.208\n",
      "Method:                 Least Squares   F-statistic:                     25.12\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):           2.24e-14\n",
      "Time:                        19:26:02   Log-Likelihood:                -357.62\n",
      "No. Observations:                 276   AIC:                             723.2\n",
      "Df Residuals:                     272   BIC:                             737.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     2.7678      0.129     21.470      0.000       2.514       3.022\n",
      "PresParty_Republican      0.5486      0.113      4.839      0.000       0.325       0.772\n",
      "SenParty_Republican       0.6159      0.117      5.258      0.000       0.385       0.847\n",
      "HouseParty_Republican     0.1823      0.131      1.390      0.166      -0.076       0.440\n",
      "==============================================================================\n",
      "Omnibus:                       44.832   Durbin-Watson:                   0.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.401\n",
      "Skew:                           0.727   Prob(JB):                     9.21e-08\n",
      "Kurtosis:                       2.162   Cond. No.                         5.09\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# added dtype = 'int' to X = ... line to convert boolean values to 0 and 1\n",
    "data = pd.read_csv('finalData.csv')\n",
    "\n",
    "# Filter the data to start from 1998-01-01 and end at 2020-12-01\n",
    "filtered_data = data[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# Remove rows with NA values in the selected columns\n",
    "filtered_data = filtered_data.dropna(subset=['PresParty', 'SenParty', 'HouseParty', 'Overall.12'])\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(filtered_data[['PresParty', 'SenParty', 'HouseParty']], drop_first=True, dtype = 'int')\n",
    "\n",
    "# # Dependent variable\n",
    "y = filtered_data['Overall.12']\n",
    "\n",
    "# # Add a constant to the independent variables (intercept term)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# # Fit the OLS regression model\n",
    "ols_model = sm.OLS(y, X)\n",
    "result = ols_model.fit()\n",
    "\n",
    "# # Print the summary of the model\n",
    "print(result.summary())\n"
=======
   "execution_count": 76,
   "id": "19c8768b-f121-4b00-a095-867a905534d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am currenlty having trouble converiting the dummy variables. myu guess is it has to do with the variuable tyoes of the X columns\n",
    "\n",
    "\n",
    "# data = pd.read_csv('finalData.csv')\n",
    "\n",
    "# # Filter the data to start from 1998-01-01 and end at 2020-12-01\n",
    "# filtered_data = data[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# # Remove rows with NA values in the selected columns\n",
    "# filtered_data = filtered_data.dropna(subset=['PresParty', 'SenParty', 'HouseParty', 'Overall.12'])\n",
    "\n",
    "# # Convert categorical variables into dummy/indicator variables\n",
    "# X = pd.get_dummies(filtered_data[['PresParty', 'SenParty', 'HouseParty']], drop_first=True)\n",
    "\n",
    "# # Dependent variable\n",
    "# y = filtered_data['Overall.12']\n",
    "\n",
    "# # Add a constant to the independent variables (intercept term)\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "# # Fit the OLS regression model\n",
    "# ols_model = sm.OLS(y, X)\n",
    "# result = ols_model.fit()\n",
    "\n",
    "# # Print the summary of the model\n",
    "# print(result.summary())\n"
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 92,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "413ce153-b27e-4a5f-b929-b1605f277b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedMinWage            float64\n",
      "GDP_AnnualGrowth      float64\n",
      "3MonthInterestRate    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Converting datatypes to float to work with OLS \n",
    "\n",
<<<<<<< HEAD
=======
    "\n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
    "data = pd.read_csv('finalData.csv')\n",
    "\n",
    "# Convert the '3MonthInterestRate' column to string type\n",
    "data['3MonthInterestRate'] = data['3MonthInterestRate'].astype(str)\n",
    "\n",
    "# Remove decimal points only when there is no number before or after it\n",
    "data['3MonthInterestRate'] = data['3MonthInterestRate'].str.replace(r'(?<!\\d)\\.|\\.(?!\\d)', '', regex=True)\n",
    "\n",
    "# Replace blanks with '0'\n",
    "data['3MonthInterestRate'] = data['3MonthInterestRate'].replace('', '0')\n",
    "\n",
    "# Convert the column to float\n",
    "data['3MonthInterestRate'] = data['3MonthInterestRate'].astype(float)\n",
    "\n",
    "# Correctly remove dollar signs from 'FedMinWage' and convert to float\n",
    "data['FedMinWage'] = data['FedMinWage'].str.replace('$', '').astype(float)\n",
    "\n",
    "# Correctly remove percent signs from 'GDP_AnnualGrowth', convert to float, and adjust for percentage representation\n",
    "data['GDP_AnnualGrowth'] = data['GDP_AnnualGrowth'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "# Display the corrected data types to ensure the operations were successful\n",
    "print(data[['FedMinWage', 'GDP_AnnualGrowth', '3MonthInterestRate']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 102,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "30e5d426-67a7-45e3-ae7f-f066f760f5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Overall.12   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.846\n",
      "Method:                 Least Squares   F-statistic:                     303.2\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):          1.58e-108\n",
<<<<<<< HEAD
      "Time:                        18:38:49   Log-Likelihood:                -130.63\n",
=======
      "Time:                        02:46:05   Log-Likelihood:                -130.63\n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "No. Observations:                 276   AIC:                             273.3\n",
      "Df Residuals:                     270   BIC:                             295.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                -16.0635      1.508    -10.653      0.000     -19.032     -13.095\n",
      "3MonthInterestRate     0.1191      0.021      5.575      0.000       0.077       0.161\n",
      "MoM Change            -0.1214      0.066     -1.830      0.068      -0.252       0.009\n",
      "Employment_Rate        0.2902      0.020     14.415      0.000       0.251       0.330\n",
      "FedMinWage            -0.1136      0.039     -2.901      0.004      -0.191      -0.036\n",
      "GDP_AnnualGrowth     -15.1985      1.461    -10.400      0.000     -18.076     -12.321\n",
      "==============================================================================\n",
      "Omnibus:                       77.508   Durbin-Watson:                   0.406\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              312.851\n",
      "Skew:                           1.113   Prob(JB):                     1.16e-68\n",
      "Kurtosis:                       7.717   Cond. No.                     4.79e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.79e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y = data['Overall.12']\n",
    "Y = Y[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "# Define the independent variables, add a constant term to the predictors\n",
    "X = data[['3MonthInterestRate', 'MoM Change', 'Employment_Rate', 'FedMinWage', 'GDP_AnnualGrowth']]\n",
    "X = X.dropna(subset=['3MonthInterestRate', 'MoM Change', 'Employment_Rate', 'FedMinWage', 'GDP_AnnualGrowth'])\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Create the OLS model\n",
    "est = sm.OLS(Y, X.astype(float)).fit()\n",
    "\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 106,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "e2f49e89-7cbd-47b5-abc4-d8e2c1ddb734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Overall.12   R-squared:                       0.768\n",
      "Model:                            OLS   Adj. R-squared:                  0.767\n",
      "Method:                 Least Squares   F-statistic:                     453.0\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):           1.87e-87\n",
<<<<<<< HEAD
      "Time:                        18:38:49   Log-Likelihood:                -189.48\n",
=======
      "Time:                        02:49:14   Log-Likelihood:                -189.48\n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "No. Observations:                 276   AIC:                             385.0\n",
      "Df Residuals:                     273   BIC:                             395.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const             -17.8486      1.556    -11.473      0.000     -20.911     -14.786\n",
      "Employment_Rate     0.3139      0.019     16.828      0.000       0.277       0.351\n",
      "FedMinWage         -0.1062      0.047     -2.261      0.025      -0.199      -0.014\n",
      "==============================================================================\n",
      "Omnibus:                      151.674   Durbin-Watson:                   0.255\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1138.587\n",
      "Skew:                           2.122   Prob(JB):                    5.74e-248\n",
      "Kurtosis:                      11.999   Cond. No.                     3.78e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.78e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter y variable\n",
    "Y = data['Overall.12']\n",
    "Y_filtered = Y[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# Filter X variables\n",
    "X = data[['Employment_Rate', 'FedMinWage']]\n",
    "X_filtered = X[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# Reset indices to align\n",
    "Y_filtered = Y_filtered.reset_index(drop=True)\n",
    "X_filtered = X_filtered.reset_index(drop=True)\n",
    "\n",
    "# Add constant to X\n",
    "X_filtered = sm.add_constant(X_filtered)\n",
    "\n",
    "# Create the OLS model\n",
    "est = sm.OLS(Y_filtered, X_filtered.astype(float)).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
<<<<<<< HEAD
    "print(est.summary())"
=======
    "print(est.summary())\n",
    "\n"
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": 88,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "232413eb-5a0b-47e3-89a9-47979ae3077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
<<<<<<< HEAD
      "Dep. Variable:             Overall.12   R-squared:                       0.768\n",
      "Model:                            OLS   Adj. R-squared:                  0.767\n",
      "Method:                 Least Squares   F-statistic:                     453.0\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):           1.87e-87\n",
      "Time:                        18:38:49   Log-Likelihood:                -189.48\n",
      "No. Observations:                 276   AIC:                             385.0\n",
      "Df Residuals:                     273   BIC:                             395.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const             -17.8486      1.556    -11.473      0.000     -20.911     -14.786\n",
      "Employment_Rate     0.3139      0.019     16.828      0.000       0.277       0.351\n",
      "FedMinWage         -0.1062      0.047     -2.261      0.025      -0.199      -0.014\n",
      "==============================================================================\n",
      "Omnibus:                      151.674   Durbin-Watson:                   0.255\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1138.587\n",
      "Skew:                           2.122   Prob(JB):                    5.74e-248\n",
      "Kurtosis:                      11.999   Cond. No.                     3.78e+03\n",
=======
      "Dep. Variable:             Overall.12   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.846\n",
      "Method:                 Least Squares   F-statistic:                     303.2\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):          1.58e-108\n",
      "Time:                        02:24:53   Log-Likelihood:                -130.63\n",
      "No. Observations:                 276   AIC:                             273.3\n",
      "Df Residuals:                     270   BIC:                             295.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                -16.0635      1.508    -10.653      0.000     -19.032     -13.095\n",
      "3MonthInterestRate     0.1191      0.021      5.575      0.000       0.077       0.161\n",
      "MoM Change            -0.1214      0.066     -1.830      0.068      -0.252       0.009\n",
      "Employment_Rate        0.2902      0.020     14.415      0.000       0.251       0.330\n",
      "FedMinWage            -0.1136      0.039     -2.901      0.004      -0.191      -0.036\n",
      "GDP_AnnualGrowth     -15.1985      1.461    -10.400      0.000     -18.076     -12.321\n",
      "==============================================================================\n",
      "Omnibus:                       77.508   Durbin-Watson:                   0.406\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              312.851\n",
      "Skew:                           1.113   Prob(JB):                     1.16e-68\n",
      "Kurtosis:                       7.717   Cond. No.                     4.79e+03\n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
<<<<<<< HEAD
      "[2] The condition number is large, 3.78e+03. This might indicate that there are\n",
=======
      "[2] The condition number is large, 4.79e+03. This might indicate that there are\n",
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Filter y variable\n",
    "Y_filtered = Y[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# Filter X variables\n",
    "X_filtered = X[(data['Date'] >= '1998-01-01') & (data['Date'] <= '2020-12-01')]\n",
    "\n",
    "# Reset indices to align\n",
    "Y_filtered = Y_filtered.reset_index(drop=True)\n",
    "X_filtered = X_filtered.reset_index(drop=True)\n",
    "\n",
    "# Add constant to X\n",
    "X_filtered = sm.add_constant(X_filtered)\n",
    "\n",
    "# Create the OLS model\n",
    "est = sm.OLS(Y_filtered, X_filtered.astype(float)).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 89,
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "id": "27d5ca46-03b5-4f02-a1cf-95a97f04c6b0",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "ValueError",
     "evalue": "The indices for endog and exog are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create the OLS model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(est\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\regression\\linear_model.py:924\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    921\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    923\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 924\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\regression\\linear_model.py:749\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 749\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    752\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\regression\\linear_model.py:203\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:89\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_constant(hasconst)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\data.py:533\u001b[0m, in \u001b[0;36mPandasData._check_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# exog can be None and we could be upcasting one or the other\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    531\u001b[0m         (\u001b[38;5;28mhasattr\u001b[39m(endog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(exog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog\u001b[38;5;241m.\u001b[39mindex)):\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indices for endog and exog are not aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_check_integrity()\n",
      "\u001b[1;31mValueError\u001b[0m: The indices for endog and exog are not aligned"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Overall.12   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.846\n",
      "Method:                 Least Squares   F-statistic:                     303.2\n",
      "Date:                Sun, 26 May 2024   Prob (F-statistic):          1.58e-108\n",
      "Time:                        02:25:54   Log-Likelihood:                -130.63\n",
      "No. Observations:                 276   AIC:                             273.3\n",
      "Df Residuals:                     270   BIC:                             295.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                -16.0635      1.508    -10.653      0.000     -19.032     -13.095\n",
      "3MonthInterestRate     0.1191      0.021      5.575      0.000       0.077       0.161\n",
      "MoM Change            -0.1214      0.066     -1.830      0.068      -0.252       0.009\n",
      "Employment_Rate        0.2902      0.020     14.415      0.000       0.251       0.330\n",
      "FedMinWage            -0.1136      0.039     -2.901      0.004      -0.191      -0.036\n",
      "GDP_AnnualGrowth     -15.1985      1.461    -10.400      0.000     -18.076     -12.321\n",
      "==============================================================================\n",
      "Omnibus:                       77.508   Durbin-Watson:                   0.406\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              312.851\n",
      "Skew:                           1.113   Prob(JB):                     1.16e-68\n",
      "Kurtosis:                       7.717   Cond. No.                     4.79e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.79e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
     ]
    }
   ],
   "source": [
    "Y = data['Paid Hourly']\n",
    "\n",
    "# Define the independent variables, add a constant term to the predictors\n",
    "X = data[['3MonthInterestRate', 'MoM Change', 'Employment_Rate', 'FedMinWage', 'GDP_AnnualGrowth']]\n",
    "X = X.dropna(subset=['3MonthInterestRate', 'MoM Change', 'Employment_Rate', 'FedMinWage', 'GDP_AnnualGrowth'])\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Create the OLS model\n",
    "est = sm.OLS(y, X.astype(float)).fit()\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "71975520-e1d4-4023-b53d-f644458f5f52",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 90,
   "id": "71975520-e1d4-4023-b53d-f644458f5f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3MonthInterestRate    float64\n",
      "MoM Change            float64\n",
      "Employment_Rate       float64\n",
      "FedMinWage            float64\n",
      "GDP_AnnualGrowth      float64\n",
      "dtype: object\n"
     ]
    }
   ],
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "source": [
    "# figuring out what datatypes are listed as for error managment\n",
    "column_types = data[['3MonthInterestRate', 'MoM Change', 'Employment_Rate', 'FedMinWage', 'GDP_AnnualGrowth']].dtypes\n",
    "print(column_types)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "id": "f18d7277-c602-4735-8f86-b3b2a08134f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "      ... \n",
      "563    9.8\n",
      "564    9.4\n",
      "565    9.0\n",
      "566    8.6\n",
      "567    NaN\n",
      "Name: 16-24, Length: 568, dtype: float64\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "f18d7277-c602-4735-8f86-b3b2a08134f5",
   "metadata": {},
   "outputs": [],
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.9"
=======
   "version": "3.11.8"
>>>>>>> 889eeaa1aaba42b7a540d2c5ad7a082794ad93ba
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
